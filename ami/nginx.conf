# This file is based on /usr/local/nginx/conf/nginx.conf.default.

# One worker process per core
error_log stderr error;

events {
    # This needed to be increased because the nginx error log said so.
    # http://nginx.org/en/docs/ngx_core_module.html#worker_connections
    worker_connections  65535;
    multi_accept on;
}

http {
    default_type  application/octet-stream;
    client_body_temp_path      /tmp;

    # turn off request logging for performance
    access_log off;

    # I think these only options affect static file serving
    sendfile        on;
    tcp_nopush      on;

    # Allow many HTTP Keep-Alive requests in a single TCP connection before
    # closing it (the default is 100). This will minimize the total number
    # of TCP connections opened/closed. The problem is that this may cause
    # some worker processes to be handling too connections relative to the
    # other workers based on an initial imbalance, so this is disabled for
    # now.
#    keepalive_requests 1000;

    #keepalive_timeout  0;
    keepalive_timeout  65;

    server {
        # For information on deferred, see:
        # http://nginx.org/en/docs/http/ngx_http_core_module.html#listen
        # http://www.techrepublic.com/article/take-advantage-of-tcp-ip-options-to-optimize-data-transmission/
        # The backlog argument to listen() is set to match net.ipv4.tcp_max_syn_backlog and net.core.somaxconn
        listen       8080 default_server deferred backlog=65535;
        server_name  localhost;

        location / {
            uwsgi_pass unix:/tmp/uwsgi.sock;
            include /usr/local/nginx/conf/uwsgi_params;
        }
    }
}










daemon off;
#user  nobody;
worker_processes  1;

error_log  ${paths:log}/error.log;
error_log  ${paths:log}/notice.log  notice;
error_log  ${paths:log}/info.log  info;

pid        ${paths:var}/nginx.pid;

events {
    worker_connections  1024;
}

http {
    server_names_hash_bucket_size 64;

    #include       mime.types;
    default_type  application/octet-stream;

    log_format  main  '$remote_addr - $remote_user [$time_local] "$request" '
                      '$status $body_bytes_sent "$http_referer" '
                      '"$http_user_agent" "$http_x_forwarded_for"';

    access_log  ${paths:log}/access.log  main;

    sendfile        on;
    tcp_nopush     on;

    #keepalive_timeout  0;
    keepalive_timeout  65;

    gzip  on;

    # Security config
    server_tokens off;
    more_set_headers 'Server';
    add_header X-Frame-Options SAMEORIGIN;
    add_header X-Content-Type-Options nosniff;
    add_header X-XSS-Protection "1; mode=block";

    # DDoS Protection Settings
    client_body_buffer_size      128k;
    large_client_header_buffers  4 256k;
    limit_conn_zone $binary_remote_addr zone=conn_limit_per_ip:10m;
    limit_req_zone $binary_remote_addr zone=req_limit_per_ip:10m rate=50r/s;
    limit_conn conn_limit_per_ip 20;
    limit_req zone=req_limit_per_ip burst=20;

    ssl_certificate      ${paths:ssl}/${config:domain}.crt;
    ssl_certificate_key  ${paths:ssl}/${config:domain}.key;
    ssl_session_cache    shared:SSL:1m;
    ssl_session_timeout  5m;
    ssl_ciphers  HIGH:!aNULL:!MD5;
    ssl_prefer_server_ciphers  on;

    server {
        listen ${config:port};
        return 301 https://$host$request_uri;
    }

    server {
        server_name  check.${config:domain};
        listen       ${config:ssl_port} ssl;


        access_log  ${paths:log}/check.${config:domain}.access.log  main;

        location / {
            root   ${paths:www};
            index  index.html index.htm;
        }

        location /nginx_status {
          stub_status on;
          access_log   off;
          allow 127.0.0.1;
          deny all;
        }
    }

    server {
        server_name  static.${config:domain};
        listen       ${config:ssl_port};

        access_log  ${paths:log}/static.${config:domain}.access.log  main;

        location / {
            proxy_pass   https://s3-eu-west-1.amazonaws.com/static.${config:domain};
        }
    }
}